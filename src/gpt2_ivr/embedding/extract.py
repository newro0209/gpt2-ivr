"""ê¸°ì¡´ ëª¨ë¸ ì„ë² ë”© ì¶”ì¶œ ë¡œì§.

GPT-2 ëª¨ë¸ì—ì„œ í† í° ì„ë² ë”©(wte)ê³¼ ìœ„ì¹˜ ì„ë² ë”©(wpe)ì„ ì¶”ì¶œí•˜ì—¬
PyTorch í…ì„œ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤. ë©”íƒ€ë°ì´í„°ë„ JSON í˜•ì‹ìœ¼ë¡œ í•¨ê»˜ ì €ì¥í•œë‹¤.
"""

from __future__ import annotations

import json
import logging
from pathlib import Path

import torch
from transformers import GPT2LMHeadModel


def extract_embeddings(
    model_name: str,
    output_dir: Path,
    logger: logging.Logger | None = None,
) -> dict[str, Path]:
    """GPT-2 ëª¨ë¸ì—ì„œ í† í° ì„ë² ë”©(wte)ê³¼ ìœ„ì¹˜ ì„ë² ë”©(wpe)ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥í•œë‹¤.

    Args:
        model_name: Hugging Face Hub ëª¨ë¸ ì´ë¦„
        output_dir: ì„ë² ë”© ì €ì¥ ë””ë ‰í† ë¦¬
        logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì‚¬í•­)

    Returns:
        ì €ì¥ëœ ì„ë² ë”© íŒŒì¼ ê²½ë¡œë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    if logger is None:
        logger = logging.getLogger("gpt2_ivr.embedding.extract")

    logger.info("ğŸ” ëª¨ë¸ ë¡œë”© ì¤‘: %s", model_name)
    model = GPT2LMHeadModel.from_pretrained(model_name, local_files_only=True)

    # ì„ë² ë”© ì¶”ì¶œ
    wte = model.transformer.wte.weight.data.clone()  # Token embeddings
    wpe = model.transformer.wpe.weight.data.clone()  # Position embeddings

    logger.info(
        "âœ… ì„ë² ë”© ì¶”ì¶œ ì™„ë£Œ - wte shape: %s, wpe shape: %s",
        wte.shape,
        wpe.shape,
    )

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    # ì„ë² ë”© ì €ì¥
    wte_path = output_dir / "original_wte.pt"
    wpe_path = output_dir / "original_wpe.pt"

    torch.save(wte, wte_path)
    torch.save(wpe, wpe_path)

    logger.info("ğŸ’¾ Token embedding ì €ì¥: %s", wte_path)
    logger.info("ğŸ’¾ Position embedding ì €ì¥: %s", wpe_path)

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        "model_name": model_name,
        "vocab_size": wte.shape[0],
        "embedding_dim": wte.shape[1],
        "max_position_embeddings": wpe.shape[0],
        "wte_shape": list(wte.shape),
        "wpe_shape": list(wpe.shape),
    }

    metadata_path = output_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    logger.info("ğŸ“‹ ë©”íƒ€ë°ì´í„° ì €ì¥: %s", metadata_path)

    return {
        "wte": wte_path,
        "wpe": wpe_path,
        "metadata": metadata_path,
    }
