"""ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™” ë¡œì§"""

from __future__ import annotations

from pathlib import Path

import torch

from gpt2_ivr.utils.logging_config import get_logger


def initialize_new_embeddings(
    reordered_embeddings_path: Path = Path("artifacts/embeddings/reordered_embeddings.pt"),
    model_save_path: Path = Path("artifacts/embeddings/initialized_model"),
    model_name_or_path: str = "openai-community/gpt2",
) -> dict[str, str]:
    """ì¬ì •ë ¬ëœ ì„ë² ë”©ì„ ëª¨ë¸ì— ì ìš©í•˜ê³  ì €ì¥
    
    Args:
        reordered_embeddings_path: ì¬ì •ë ¬ëœ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ
        model_save_path: ì´ˆê¸°í™”ëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        model_name_or_path: ê¸°ë³¸ ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
        
    Returns:
        ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    logger = get_logger("gpt2_ivr.embedding.init_new")
    
    from transformers import AutoConfig, AutoModelForCausalLM
    
    # ì¬ì •ë ¬ëœ ì„ë² ë”© ë¡œë“œ
    logger.info(f"ğŸ“‚ ì¬ì •ë ¬ëœ ì„ë² ë”© ë¡œë“œ: {reordered_embeddings_path}")
    embeddings = torch.load(reordered_embeddings_path)
    new_wte = embeddings["wte"]
    new_lm_head = embeddings["lm_head"]
    
    new_vocab_size = new_wte.shape[0]
    logger.info(f"ğŸ“Š ìƒˆ vocab size: {new_vocab_size}")
    
    # ëª¨ë¸ ë¡œë“œ
    logger.info(f"ğŸ¤– ëª¨ë¸ ë¡œë“œ: {model_name_or_path}")
    config = AutoConfig.from_pretrained(model_name_or_path)
    config.vocab_size = new_vocab_size
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name_or_path,
        config=config,
        ignore_mismatched_sizes=True,
    )
    
    # ì„ë² ë”© ë ˆì´ì–´ í¬ê¸° ì¡°ì •
    model.resize_token_embeddings(new_vocab_size)
    
    # ì¬ì •ë ¬ëœ ì„ë² ë”© ì ìš©
    logger.info("ğŸ”§ ì¬ì •ë ¬ëœ ì„ë² ë”©ì„ ëª¨ë¸ì— ì ìš©")
    with torch.no_grad():
        model.get_input_embeddings().weight.copy_(new_wte)
        model.get_output_embeddings().weight.copy_(new_lm_head)
    
    # ëª¨ë¸ ì €ì¥
    model_save_path.mkdir(parents=True, exist_ok=True)
    model.save_pretrained(str(model_save_path))
    logger.info(f"ğŸ’¾ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì €ì¥: {model_save_path}")
    
    logger.info("âœ… ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™” ì™„ë£Œ")
    
    return {
        "status": "success",
        "model_path": str(model_save_path),
        "vocab_size": new_vocab_size,
    }
