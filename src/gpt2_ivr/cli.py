"""GPT2-IVR CLI ì§„ì…ì  ëª¨ë“ˆ.

Tokenizer Model Migration + IVR íŒŒì´í”„ë¼ì¸ì˜ ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•œë‹¤.
Rich ê¸°ë°˜ ì½˜ì†” ì¶œë ¥ ë° ë¡œê¹…ì„ ì§€ì›í•œë‹¤.
"""

from __future__ import annotations

import argparse
import logging
from collections.abc import Callable
from dataclasses import dataclass
from datetime import datetime
from functools import lru_cache, partial
from pathlib import Path
from time import perf_counter
from typing import Any

from rich.console import Console
from rich.logging import RichHandler
from rich.panel import Panel
from rich.table import Table
from rich.text import Text

from gpt2_ivr.commands import (
    AlignCommand,
    AnalyzeCommand,
    Command,
    DistillCommand,
    InitCommand,
    RemapCommand,
    SelectCommand,
    TrainCommand,
)
from gpt2_ivr.constants import (
    BPE_TOKEN_ID_SEQUENCES_FILE,
    CORPORA_CLEANED_DIR,
    CORPORA_RAW_DIR,
    EMBEDDINGS_ROOT,
    LOGS_DIR,
    REPLACEMENT_CANDIDATES_FILE,
    SELECTION_LOG_FILE,
    TOKENIZER_DISTILLED_UNIGRAM_DIR,
    TOKENIZER_ORIGINAL_DIR,
    TOKENIZER_REMAPPED_DIR,
    TOKEN_FREQUENCY_FILE,
)

LOGGER_NAME = "gpt2_ivr.cli"
REMAP_RULES_PATH = Path("src/gpt2_ivr/tokenizer/remap_rules.yaml")
CONSOLE = Console(stderr=False)


# Command registry for Factory pattern
_COMMAND_REGISTRY: dict[str, Callable[[argparse.Namespace], Command]] = {}


def register_command(name: str) -> Callable:
    """ì»¤ë§¨ë“œ íŒ©í† ë¦¬ í•¨ìˆ˜ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í•˜ëŠ” ë°ì½”ë ˆì´í„°.

    Args:
        name: ì»¤ë§¨ë“œ ì´ë¦„ (CLI ì„œë¸Œì»¤ë§¨ë“œ ì´ë¦„)

    Returns:
        ë°ì½”ë ˆì´í„° í•¨ìˆ˜
    """
    def decorator(factory: Callable[[argparse.Namespace], Command]) -> Callable:
        _COMMAND_REGISTRY[name] = factory
        return factory
    return decorator


@dataclass
class ArgConfig:
    """ê³µí†µ ì¸ì ì„¤ì •ì„ ë‹´ëŠ” ë°ì´í„°í´ë˜ìŠ¤."""
    flag: str
    type: type = str
    default: Any = None
    help: str = ""
    action: str | None = None
    choices: list[str] | None = None


# ê³µí†µ ì¸ì ì„¤ì • (ë°ì´í„° ê¸°ë°˜)
COMMON_ARG_CONFIGS = {
    "tokenizer-dir": ArgConfig("--tokenizer-dir", Path, TOKENIZER_ORIGINAL_DIR, "ì›ë³¸ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬"),
    "original-tokenizer-dir": ArgConfig("--original-tokenizer-dir", Path, TOKENIZER_ORIGINAL_DIR, "ì›ë³¸ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬"),
    "distilled-tokenizer-dir": ArgConfig("--distilled-tokenizer-dir", Path, TOKENIZER_DISTILLED_UNIGRAM_DIR, "ì¦ë¥˜ëœ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬"),
    "remapped-tokenizer-dir": ArgConfig("--remapped-tokenizer-dir", Path, TOKENIZER_REMAPPED_DIR, "ì¬í• ë‹¹ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬"),
    "remap-rules-path": ArgConfig("--remap-rules-path", Path, REMAP_RULES_PATH, "ì¬í• ë‹¹ ê·œì¹™ íŒŒì¼ ê²½ë¡œ"),
}


class CliHelpFormatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawTextHelpFormatter):
    """CLI ë„ì›€ë§ í¬ë§·í„°.

    ArgumentDefaultsHelpFormatterì™€ RawTextHelpFormatterë¥¼ ê²°í•©í•˜ì—¬
    ê¸°ë³¸ê°’ í‘œì‹œì™€ ì›ì‹œ í…ìŠ¤íŠ¸ í¬ë§·ì„ ë™ì‹œì— ì§€ì›í•œë‹¤.
    """


class CliArgumentParser(argparse.ArgumentParser):
    """ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ Rich ìŠ¤íƒ€ì¼ë¡œ ì¶œë ¥í•˜ëŠ” argparse íŒŒì„œ.

    ì¸ì íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ ì‹œ Rich Panelë¡œ ì˜¤ë¥˜ë¥¼ í‘œì‹œí•˜ì—¬
    ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•œë‹¤.
    """

    def error(self, message: str) -> None:
        """ì¸ì íŒŒì‹± ì˜¤ë¥˜ë¥¼ Rich íŒ¨ë„ë¡œ ì¶œë ¥í•œë‹¤.

        Args:
            message: ì˜¤ë¥˜ ë©”ì‹œì§€
        """
        CONSOLE.print(
            Panel.fit(
                f"[bold red]ì¸ì ì˜¤ë¥˜[/bold red]\n{message}\n\n[dim]ë„ì›€ë§: uv run ivr --help[/dim]",
                title="CLI ì…ë ¥ ì˜¤ë¥˜",
                border_style="red",
            )
        )
        raise SystemExit(2)


def validate_int(value: str, minimum: int = 0) -> int:
    """ì •ìˆ˜ ê°’ì„ ê²€ì¦í•œë‹¤.

    Args:
        value: íŒŒì‹±í•  ë¬¸ìì—´ ê°’
        minimum: í—ˆìš©ë˜ëŠ” ìµœì†Œê°’ (ê¸°ë³¸ê°’: 0)

    Returns:
        íŒŒì‹±ëœ ì •ìˆ˜ ê°’

    Raises:
        argparse.ArgumentTypeError: ê°’ì´ ì •ìˆ˜ê°€ ì•„ë‹ˆê±°ë‚˜ ìµœì†Œê°’ë³´ë‹¤ ì‘ì€ ê²½ìš°
    """
    try:
        if (parsed := int(value)) < minimum:
            raise argparse.ArgumentTypeError(f"{minimum} ì´ìƒì˜ ì •ìˆ˜ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")
        return parsed
    except ValueError as e:
        raise argparse.ArgumentTypeError("ì •ìˆ˜ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.") from e


# Partial applicationìœ¼ë¡œ ì¤‘ë³µ ì œê±°
non_negative_int = partial(validate_int, minimum=0)
positive_int = partial(validate_int, minimum=1)


def add_common_args(parser: argparse.ArgumentParser, *args: str) -> None:
    """ê³µí†µ ì¸ìë¥¼ íŒŒì„œì— ì¶”ê°€í•œë‹¤.

    COMMON_ARG_CONFIGSì—ì„œ ì„¤ì •ì„ ì¡°íšŒí•˜ì—¬ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¸ìë¥¼ ì¶”ê°€í•œë‹¤.

    Args:
        parser: ì¸ìë¥¼ ì¶”ê°€í•  íŒŒì„œ
        *args: ì¶”ê°€í•  ì¸ì ì´ë¦„ë“¤ (COMMON_ARG_CONFIGSì˜ í‚¤)
    """
    for arg in args:
        if config := COMMON_ARG_CONFIGS.get(arg):
            kwargs = {"type": config.type, "default": config.default, "help": config.help}
            if config.action:
                kwargs["action"] = config.action
            if config.choices:
                kwargs["choices"] = config.choices
            parser.add_argument(config.flag, **kwargs)


def setup_subparsers(subparsers: argparse._SubParsersAction) -> None:
    """ëª¨ë“  ì„œë¸Œì»¤ë§¨ë“œ íŒŒì„œë¥¼ ì„¤ì •í•œë‹¤.

    Args:
        subparsers: ì„œë¸ŒíŒŒì„œ ì•¡ì…˜ ê°ì²´
    """
    # init
    init_parser = subparsers.add_parser("init", help="ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”", formatter_class=CliHelpFormatter)
    init_parser.add_argument("--model-name", default="openai-community/gpt2", help="Hugging Face Hub ëª¨ë¸ ì´ë¦„")
    init_parser.add_argument(
        "--tokenizer-dir", type=Path, default=TOKENIZER_ORIGINAL_DIR, help="í† í¬ë‚˜ì´ì € ì €ì¥ ë””ë ‰í† ë¦¬"
    )
    init_parser.add_argument("--force", action="store_true", help="ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ")
    init_parser.add_argument(
        "--raw-corpora-dir",
        type=Path,
        default=CORPORA_RAW_DIR,
        help="raw ì½”í¼ìŠ¤ê°€ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬",
    )
    init_parser.add_argument(
        "--cleaned-corpora-dir",
        type=Path,
        default=CORPORA_CLEANED_DIR,
        help="ì •ì œëœ ì½”í¼ìŠ¤ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬",
    )
    init_parser.add_argument("--text-key", default="text", help="JSON/JSONL íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ì˜¬ í‚¤")
    init_parser.add_argument("--encoding", default="utf-8", help="ì…ë ¥ ì½”í¼ìŠ¤ íŒŒì¼ ì¸ì½”ë”©")
    init_parser.add_argument(
        "--normalize-force",
        action="store_true",
        help="ì´ë¯¸ ì •ì œë³¸ì´ ìˆì–´ë„ raw íŒŒì¼ì„ ë‹¤ì‹œ ë³€í™˜í•©ë‹ˆë‹¤",
    )

    # analyze
    analyze_parser = subparsers.add_parser("analyze", help="BPE í† í° ì‹œí€€ìŠ¤ ë¶„ì„", formatter_class=CliHelpFormatter)
    analyze_parser.add_argument("--input-dir", type=Path, default=CORPORA_CLEANED_DIR, help="ì½”í¼ìŠ¤ ì…ë ¥ ë””ë ‰í† ë¦¬")
    analyze_parser.add_argument(
        "--output-sequences", type=Path, default=BPE_TOKEN_ID_SEQUENCES_FILE, help="BPE í† í° ì‹œí€€ìŠ¤ ì¶œë ¥ ê²½ë¡œ"
    )
    analyze_parser.add_argument(
        "--output-frequency", type=Path, default=TOKEN_FREQUENCY_FILE, help="í† í° ë¹ˆë„ parquet ì¶œë ¥ ê²½ë¡œ"
    )
    add_common_args(analyze_parser, "tokenizer-dir")
    analyze_parser.add_argument("--workers", type=non_negative_int, default=0, help="ìŠ¤ë ˆë“œ ì›Œì»¤ ìˆ˜ (0ì´ë©´ CPU - 1)")
    analyze_parser.add_argument(
        "--chunk-size", type=non_negative_int, default=0, help="ìŠ¤ë ˆë“œ ì²­í¬ í¬ê¸°(0ì´ë©´ ìë™ ì„¤ì •)"
    )
    analyze_parser.add_argument(
        "--max-texts", type=non_negative_int, default=0, help="ì²˜ë¦¬í•  ìµœëŒ€ í…ìŠ¤íŠ¸ ìˆ˜ (0ì´ë©´ ì „ì²´)"
    )
    analyze_parser.add_argument("--encoding", default="utf-8", help="ì…ë ¥ íŒŒì¼ ì¸ì½”ë”©")

    # distill-tokenizer
    distill_parser = subparsers.add_parser(
        "distill-tokenizer", help="BPE -> Unigram distillation", formatter_class=CliHelpFormatter
    )
    add_common_args(distill_parser, "original-tokenizer-dir", "distilled-tokenizer-dir")
    distill_parser.add_argument("--corpus-dir", type=Path, default=CORPORA_CLEANED_DIR, help="í•™ìŠµ ì½”í¼ìŠ¤ ë””ë ‰í† ë¦¬")

    # select
    select_parser = subparsers.add_parser("select", help="IVR ëŒ€ìƒ í† í° ì„ ì •", formatter_class=CliHelpFormatter)
    select_parser.add_argument(
        "--frequency-path", type=Path, default=TOKEN_FREQUENCY_FILE, help="í† í° ë¹ˆë„ parquet íŒŒì¼ ê²½ë¡œ"
    )
    select_parser.add_argument(
        "--sequences-path", type=Path, default=BPE_TOKEN_ID_SEQUENCES_FILE, help="BPE í† í° ì‹œí€€ìŠ¤ íŒŒì¼ ê²½ë¡œ"
    )
    select_parser.add_argument(
        "--output-csv", type=Path, default=REPLACEMENT_CANDIDATES_FILE, help="êµì²´ í›„ë³´ CSV ì €ì¥ ê²½ë¡œ"
    )
    select_parser.add_argument("--output-log", type=Path, default=SELECTION_LOG_FILE, help="ì„ ì • ë¡œê·¸ ì €ì¥ ê²½ë¡œ")
    add_common_args(select_parser, "tokenizer-dir")
    select_parser.add_argument("--max-candidates", type=positive_int, default=1000, help="ìµœëŒ€ í›„ë³´ ê°œìˆ˜")
    select_parser.add_argument("--min-token-len", type=positive_int, default=2, help="ë³´í˜¸ í† í° ìµœì†Œ ê¸¸ì´")

    # remap
    remap_parser = subparsers.add_parser("remap", help="í† í° ì¬í• ë‹¹ ê·œì¹™ ì ìš©", formatter_class=CliHelpFormatter)
    add_common_args(remap_parser, "distilled-tokenizer-dir", "remapped-tokenizer-dir", "remap-rules-path")
    remap_parser.add_argument(
        "--replacement-candidates-path", type=Path, default=REPLACEMENT_CANDIDATES_FILE, help="êµì²´ í›„ë³´ CSV ê²½ë¡œ"
    )

    # align
    align_parser = subparsers.add_parser("align", help="ì„ë² ë”© ì¬ì •ë ¬", formatter_class=CliHelpFormatter)
    align_parser.add_argument("--model-name", default="openai-community/gpt2", help="GPT-2 ëª¨ë¸ ì´ë¦„")
    add_common_args(align_parser, "original-tokenizer-dir", "remapped-tokenizer-dir", "remap-rules-path")
    align_parser.add_argument(
        "--embeddings-output-dir", type=Path, default=EMBEDDINGS_ROOT, help="ì„ë² ë”© ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    align_parser.add_argument(
        "--init-strategy", default="mean", choices=["mean", "random", "zeros"], help="ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™” ì „ëµ"
    )

    # train
    subparsers.add_parser("train", help="ë¯¸ì„¸ì¡°ì •", formatter_class=CliHelpFormatter)


def setup_parser() -> argparse.ArgumentParser:
    """CLI íŒŒì„œë¥¼ ì„¤ì •í•œë‹¤.

    Returns:
        ì„¤ì •ëœ ArgumentParser ê°ì²´
    """
    parser = CliArgumentParser(
        prog="ivr",
        description="Tokenizer Model Migration + IVR íŒŒì´í”„ë¼ì¸ CLI",
        formatter_class=CliHelpFormatter,
    )
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="ì½˜ì†” ë¡œê¹… ë ˆë²¨",
    )

    subparsers = parser.add_subparsers(dest="command", required=True, metavar="command")
    setup_subparsers(subparsers)

    return parser


def setup_logging(log_level: str) -> logging.Logger:
    """ë¡œê¹…ì„ ì„¤ì •í•œë‹¤.

    Rich ì½˜ì†” í•¸ë“¤ëŸ¬ì™€ íŒŒì¼ í•¸ë“¤ëŸ¬ë¥¼ ëª¨ë‘ ì„¤ì •í•œë‹¤.

    Args:
        log_level: ë¡œê¹… ë ˆë²¨ ë¬¸ìì—´ (DEBUG, INFO, WARNING, ERROR)

    Returns:
        ì„¤ì •ëœ ë¡œê±° ê°ì²´
    """
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level.upper(), logging.INFO))

    # Rich ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = RichHandler(rich_tracebacks=True, markup=True, console=CONSOLE, show_time=False)
    console_handler.setFormatter(logging.Formatter("%(message)s"))
    root_logger.addHandler(console_handler)

    # íŒŒì¼ í•¸ë“¤ëŸ¬
    LOGS_DIR.mkdir(parents=True, exist_ok=True)
    log_file = LOGS_DIR / f"ivr_{datetime.now():%Y%m%d_%H%M%S}.log"

    file_handler = logging.FileHandler(log_file, encoding="utf-8")
    file_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s"))
    root_logger.addHandler(file_handler)

    root_logger.info("%sì— ë¡œê·¸ íŒŒì¼ ìƒì„± ì™„ë£Œ", log_file)
    return logging.getLogger(LOGGER_NAME)


@lru_cache(maxsize=1)
def _get_banner() -> str:
    """ë°°ë„ˆ í…ìŠ¤íŠ¸ë¥¼ ìºì‹±í•˜ì—¬ ë°˜í™˜í•œë‹¤.

    pyfigletì„ ì‚¬ìš©í•˜ì—¬ ASCII ì•„íŠ¸ ë°°ë„ˆë¥¼ ìƒì„±í•˜ê³ , LRU ìºì‹œë¡œ ì¬ì‚¬ìš©í•œë‹¤.

    Returns:
        ìƒì„±ëœ ë°°ë„ˆ í…ìŠ¤íŠ¸
    """
    from pyfiglet import Figlet
    return Figlet(font="standard").renderText("IVR").rstrip()


def print_banner() -> None:
    """ì‹œì‘ ë°°ë„ˆë¥¼ ì¶œë ¥í•œë‹¤."""
    CONSOLE.print(Text(_get_banner(), style="bold cyan"))


# Command factory functions (Registry pattern)
@register_command("init")
def _create_init_command(a: argparse.Namespace) -> InitCommand:
    """InitCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return InitCommand(
        a.model_name, a.tokenizer_dir, a.force, a.raw_corpora_dir,
        a.cleaned_corpora_dir, a.text_key, a.encoding, a.normalize_force
    )


@register_command("analyze")
def _create_analyze_command(a: argparse.Namespace) -> AnalyzeCommand:
    """AnalyzeCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return AnalyzeCommand(
        a.input_dir, a.output_sequences, a.output_frequency,
        a.tokenizer_dir, a.workers, a.chunk_size, a.max_texts, a.encoding
    )


@register_command("distill-tokenizer")
def _create_distill_command(a: argparse.Namespace) -> DistillCommand:
    """DistillCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return DistillCommand(a.original_tokenizer_dir, a.distilled_tokenizer_dir, a.corpus_dir)


@register_command("select")
def _create_select_command(a: argparse.Namespace) -> SelectCommand:
    """SelectCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return SelectCommand(
        a.frequency_path, a.sequences_path, a.output_csv, a.output_log,
        a.tokenizer_dir, a.max_candidates, a.min_token_len
    )


@register_command("remap")
def _create_remap_command(a: argparse.Namespace) -> RemapCommand:
    """RemapCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return RemapCommand(
        a.distilled_tokenizer_dir, a.remapped_tokenizer_dir,
        a.remap_rules_path, a.replacement_candidates_path
    )


@register_command("align")
def _create_align_command(a: argparse.Namespace) -> AlignCommand:
    """AlignCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return AlignCommand(
        a.model_name, a.original_tokenizer_dir, a.remapped_tokenizer_dir,
        a.remap_rules_path, a.embeddings_output_dir, a.init_strategy
    )


@register_command("train")
def _create_train_command(a: argparse.Namespace) -> TrainCommand:
    """TrainCommand íŒ©í† ë¦¬ í•¨ìˆ˜."""
    return TrainCommand()


def create_command(args: argparse.Namespace) -> Command:
    """ì»¤ë§¨ë“œ ê°ì²´ë¥¼ ìƒì„±í•œë‹¤.

    Factory Registry íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì»¤ë§¨ë“œ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜ë¥¼ ì¡°íšŒí•˜ê³  ì‹¤í–‰í•œë‹¤.

    Args:
        args: íŒŒì‹±ëœ ì»¤ë§¨ë“œë¼ì¸ ì¸ì

    Returns:
        ìƒì„±ëœ Command ê°ì²´

    Raises:
        NotImplementedError: ìœ íš¨í•˜ì§€ ì•Šì€ ì»¤ë§¨ë“œì¸ ê²½ìš°
    """
    if factory := _COMMAND_REGISTRY.get(args.command):
        return factory(args)
    raise NotImplementedError(f"'{args.command}'ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ì»¤ë§¨ë“œì…ë‹ˆë‹¤.")


def format_time(elapsed: float) -> str:
    """ê²½ê³¼ ì‹œê°„ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…í•œë‹¤.

    1ì´ˆ ë¯¸ë§Œì€ ë°€ë¦¬ì´ˆ, 1ë¶„ ë¯¸ë§Œì€ ì´ˆ, ê·¸ ì´ìƒì€ ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•œë‹¤.

    Args:
        elapsed: ê²½ê³¼ ì‹œê°„ (ì´ˆ ë‹¨ìœ„)

    Returns:
        í¬ë§·íŒ…ëœ ì‹œê°„ ë¬¸ìì—´ (ì˜ˆ: "500ms", "3.14ì´ˆ", "2ë¶„ 30.5ì´ˆ")
    """
    if elapsed < 1:
        return f"{elapsed*1000:.0f}ms"
    if elapsed < 60:
        return f"{elapsed:.2f}ì´ˆ"
    minutes, seconds = divmod(elapsed, 60)
    return f"{int(minutes)}ë¶„ {seconds:.1f}ì´ˆ"


def format_value(value: Any) -> str:
    """ê²°ê³¼ ê°’ì„ í¬ë§·íŒ…í•œë‹¤.

    íƒ€ì…ë³„ë¡œ ì ì ˆí•œ í¬ë§·í„°ë¥¼ ì ìš©í•˜ê³ , 120ìë¥¼ ì´ˆê³¼í•˜ë©´ ì˜ë¼ë‚¸ë‹¤.

    Args:
        value: í¬ë§·íŒ…í•  ê°’ (Any íƒ€ì…)

    Returns:
        í¬ë§·íŒ…ëœ ë¬¸ìì—´ (120ì ì´ˆê³¼ ì‹œ "..." ì¶”ê°€)
    """
    formatters = {
        Path: str,
        dict: lambda v: f"dict({len(v)})",
        list: lambda v: f"list({len(v)})",
    }
    formatted = formatters.get(type(value), str)(value)
    return formatted[:117] + "..." if len(formatted) > 120 else formatted


def create_result_table(command_name: str, elapsed: float, result: dict[str, Any]) -> Panel:
    """ì‹¤í–‰ ê²°ê³¼ í…Œì´ë¸”ì„ ìƒì„±í•œë‹¤.

    Args:
        command_name: ì»¤ë§¨ë“œ ì´ë¦„
        elapsed: ê²½ê³¼ ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
        result: ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬

    Returns:
        ìƒì„±ëœ Rich Panel ê°ì²´
    """
    table = Table(show_header=True, border_style="dim", padding=(0, 1))
    table.add_column("í•­ëª©", style="bold cyan", width=25)
    table.add_column("ê°’", style="yellow", justify="left")

    table.add_row("â±ï¸  ì‹¤í–‰ ì‹œê°„", format_time(elapsed))

    for key, value in result.items():
        formatted_key = key.replace("_", " ").title()
        table.add_row(f"   {formatted_key}", format_value(value))

    return Panel(
        table,
        title=f"[bold green]âœ… {command_name} ì™„ë£Œ[/bold green]",
        border_style="green",
        padding=(1, 2)
    )


# Error categorization strategy (Strategy pattern)
_ERROR_CATEGORIES = {
    NotImplementedError: ("ë¯¸êµ¬í˜„ ê¸°ëŠ¥", "âš ï¸", "ë¯¸êµ¬í˜„/ë¯¸ì§€ì› ì˜¤ë¥˜"),
    FileNotFoundError: ("íŒŒì¼ ì—†ìŒ", "ğŸ“", "íŒŒì¼ ì°¾ê¸° ì‹¤íŒ¨"),
    ValueError: ("ì…ë ¥ê°’ ì˜¤ë¥˜", "âš ï¸", "ì…ë ¥ê°’ ì˜¤ë¥˜"),
}


def handle_error(error: Exception, command: str, elapsed: float, logger: logging.Logger) -> None:
    """ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ê³  ì¶œë ¥í•œë‹¤.

    Strategy íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì—ëŸ¬ íƒ€ì…ë³„ë¡œ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ì™€ ì•„ì´ì½˜ì„ ì„ íƒí•œë‹¤.

    Args:
        error: ë°œìƒí•œ ì˜ˆì™¸
        command: ì‹¤í–‰ ì¤‘ì´ë˜ ì»¤ë§¨ë“œ ì´ë¦„
        elapsed: ê²½ê³¼ ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
        logger: ë¡œê±° ê°ì²´
    """
    error_type = type(error).__name__
    category, icon, log_msg = _ERROR_CATEGORIES.get(type(error), ("ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜", "âŒ", "ì‹¤í–‰ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ"))

    # ë¡œê¹…
    if type(error) in _ERROR_CATEGORIES:
        logger.error("[%s] %s: %s", command, log_msg, error)
    else:
        logger.exception("[%s] %s", command, log_msg)

    # Rich í…Œì´ë¸”ë¡œ ì—ëŸ¬ ì •ë³´ êµ¬ì„±
    error_table = Table(show_header=False, border_style="dim red", padding=(0, 1))
    error_table.add_column("í•­ëª©", style="bold red", width=15)
    error_table.add_column("ë‚´ìš©", style="white")

    error_table.add_row("ì¹´í…Œê³ ë¦¬", f"{icon} {category}")
    error_table.add_row("ì˜¤ë¥˜ íƒ€ì…", error_type)
    error_table.add_row("ë©”ì‹œì§€", str(error))
    error_table.add_row("ê²½ê³¼ ì‹œê°„", format_time(elapsed))

    # Panelë¡œ ê°ì‹¸ì„œ ì¶œë ¥
    CONSOLE.print()
    CONSOLE.print(
        Panel(error_table, title=f"[bold red]âŒ {command} ì‹¤í–‰ ì‹¤íŒ¨[/bold red]",
              border_style="red", padding=(1, 2))
    )
    CONSOLE.print()

    # ë„ì›€ë§ ì œì•ˆ
    help_text = Text()
    help_text.append("ğŸ’¡ ë„ì›€ë§: ", style="bold yellow")
    help_text.append(f"ivr {command} --help", style="cyan")
    help_text.append(" ëª…ë ¹ìœ¼ë¡œ ìƒì„¸ ì˜µì…˜ì„ í™•ì¸í•˜ì„¸ìš”", style="dim")
    CONSOLE.print(help_text)
    CONSOLE.print()


def main() -> int:
    """CLI ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸.

    íŒŒì´í”„ë¼ì¸ ëª…ë ¹ì–´ë¥¼ íŒŒì‹±í•˜ê³  ì‹¤í–‰í•œë‹¤. ê° ë‹¨ê³„ë³„ ëª…ë ¹ì–´ëŠ”
    ì„œë¸Œì»¤ë§¨ë“œë¡œ ì œê³µë˜ë©°, Rich ê¸°ë°˜ ì½˜ì†” ì¶œë ¥ê³¼ íŒŒì¼ ë¡œê¹…ì„ ì§€ì›í•œë‹¤.

    Returns:
        ì¢…ë£Œ ì½”ë“œ (0: ì„±ê³µ, 1: ì˜¤ë¥˜, 130: ì‚¬ìš©ì ì¤‘ë‹¨)
    """
    print_banner()
    args = setup_parser().parse_args()
    logger = setup_logging(args.log_level)
    start = perf_counter()

    try:
        command = create_command(args)
        command_name = command.get_name()
        logger.info("[%s] ë‹¨ê³„ ì‹œì‘", command_name)
        result = command.execute()
        elapsed = perf_counter() - start

        logger.info("[%s] ë‹¨ê³„ ì™„ë£Œ (%.2fs)", command_name, elapsed)
        CONSOLE.print(create_result_table(command_name, elapsed, result))
        return 0

    except KeyboardInterrupt:
        logger.warning("ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ë‹¨ë¨")
        return 130

    except Exception as e:
        handle_error(e, args.command, perf_counter() - start, logger)
        return 1


if __name__ == "__main__":
    raise SystemExit(main())
