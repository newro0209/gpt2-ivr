"""ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì´ˆê¸°í™” ì»¤ë§¨ë“œ.

Hugging Face Hubì—ì„œ GPT-2 ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬
ë¡œì»¬ì— ì €ì¥í•˜ëŠ” ì´ˆê¸°í™” ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•œë‹¤.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any

from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from gpt2_ivr.corpus.normalize import normalize_raw_corpora
from gpt2_ivr.tokenizer import initialize_assets

from .base import Command

console = Console()


class InitCommand(Command):
    """ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì´ˆê¸°í™” ì»¤ë§¨ë“œ.

    Hugging Face Hubì—ì„œ ì§€ì •ëœ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬
    ë¡œì»¬ ë””ë ‰í† ë¦¬ì— ì €ì¥í•œë‹¤.

    Attributes:
        model_name: Hugging Face Hub ëª¨ë¸ ì´ë¦„
        tokenizer_dir: í† í¬ë‚˜ì´ì € ì €ì¥ ë””ë ‰í† ë¦¬
        force: ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ë„ ì¬ë‹¤ìš´ë¡œë“œ ì—¬ë¶€
        raw_corpora_dir: ì •ì œ ì „ ì›ë³¸ ì½”í¼ìŠ¤ ë””ë ‰í† ë¦¬
        cleaned_corpora_dir: ì •ì œëœ ì½”í¼ìŠ¤ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
        text_key: JSON/JSONL íŒŒì¼ì—ì„œ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ í‚¤
        encoding: ì½”í¼ìŠ¤ íŒŒì¼ ì¸ì½”ë”©
        normalize_force: ì¡´ì¬í•˜ëŠ” ì •ì œë³¸ì´ ìˆì–´ë„ ë®ì–´ì“¸ì§€ ì—¬ë¶€
    """

    def __init__(
        self,
        model_name: str,
        tokenizer_dir: Path,
        force: bool,
        raw_corpora_dir: Path,
        cleaned_corpora_dir: Path,
        text_key: str,
        encoding: str,
        normalize_force: bool,
    ):
        self.model_name = model_name
        self.tokenizer_dir = tokenizer_dir
        self.force = force
        self.raw_corpora_dir = raw_corpora_dir
        self.cleaned_corpora_dir = cleaned_corpora_dir
        self.text_key = text_key
        self.encoding = encoding
        self.normalize_force = normalize_force

    def execute(self, **kwargs: Any) -> dict[str, Any]:
        """í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”ë¥¼ ì‹¤í–‰í•œë‹¤.

        Args:
            **kwargs: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

        Returns:
            ì´ˆê¸°í™” ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (tokenizer_dir, vocab_size, model_name)
        """
        result = initialize_assets(
            model_name=self.model_name,
            tokenizer_dir=self.tokenizer_dir,
            force=self.force,
        )

        normalized_corpora = normalize_raw_corpora(
            raw_dir=self.raw_corpora_dir,
            cleaned_dir=self.cleaned_corpora_dir,
            text_key=self.text_key,
            encoding=self.encoding,
            force=self.normalize_force,
        )

        # Rich í…Œì´ë¸”ë¡œ ê²°ê³¼ ì¶œë ¥
        table = Table(title="ğŸš€ ì´ˆê¸°í™” ì™„ë£Œ", show_header=True, title_style="bold green")
        table.add_column("í•­ëª©", style="bold cyan", width=25)
        table.add_column("ê°’", style="yellow", justify="left")

        table.add_row("ëª¨ë¸", f"[bold]{result['model_name']}[/bold]")
        table.add_row("Vocab í¬ê¸°", f"{result['vocab_size']:,}ê°œ")
        table.add_row("", "")  # ë¹ˆ ì¤„
        table.add_row("í† í¬ë‚˜ì´ì € ê²½ë¡œ", str(result["tokenizer_dir"]))
        table.add_row("ì •ì œëœ ì½”í¼ìŠ¤", f"{len(normalized_corpora):,}ê°œ íŒŒì¼")
        table.add_row("ì½”í¼ìŠ¤ ê²½ë¡œ", str(self.cleaned_corpora_dir))

        console.print()
        console.print(table)
        console.print()

        # ì„±ê³µ ë©”ì‹œì§€
        console.print(Panel(
            "[bold green]âœ… ëª¨ë¸ ë° ì½”í¼ìŠ¤ ì´ˆê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤[/bold green]\n"
            "[dim]ë‹¤ìŒ ë‹¨ê³„: [cyan]ivr analyze[/cyan] ëª…ë ¹ìœ¼ë¡œ í† í° ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”[/dim]",
            border_style="green",
            padding=(1, 2)
        ))
        console.print()

        return {
            "tokenizer_dir": result["tokenizer_dir"],
            "vocab_size": result["vocab_size"],
            "model_name": result["model_name"],
            "normalized_corpora": len(normalized_corpora),
            "cleaned_dir": self.cleaned_corpora_dir,
        }

    def get_name(self) -> str:
        """ì»¤ë§¨ë“œ ì´ë¦„ì„ ë°˜í™˜í•œë‹¤.

        Returns:
            ì»¤ë§¨ë“œ ì´ë¦„ "init"
        """
        return "init"
