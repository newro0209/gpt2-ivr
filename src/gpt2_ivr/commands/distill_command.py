"""í† í¬ë‚˜ì´ì € ì¦ë¥˜ ì»¤ë§¨ë“œ.

GPT-2 BPE í† í¬ë‚˜ì´ì €ë¥¼ Unigram ëª¨ë¸ë¡œ ì¦ë¥˜í•˜ëŠ” ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•œë‹¤.
ì›ë³¸ í† í¬ë‚˜ì´ì €ì˜ ì–´íœ˜ í¬ê¸°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì½”í¼ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œë‹¤.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any

from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from gpt2_ivr.constants import (
    CORPORA_CLEANED_DIR,
    TOKENIZER_DISTILLED_UNIGRAM_DIR,
    TOKENIZER_ORIGINAL_DIR,
)
from gpt2_ivr.parser import CliHelpFormatter

from .base import Command, SubparsersLike


class DistillCommand(Command):
    """í† í¬ë‚˜ì´ì € ì¦ë¥˜ ì»¤ë§¨ë“œ.

    BPE í† í¬ë‚˜ì´ì €ë¥¼ Unigram ëª¨ë¸ë¡œ ì¦ë¥˜í•˜ì—¬ ì›ë³¸ê³¼ ìœ ì‚¬í•œ ë™ì‘ì„ í•˜ì§€ë§Œ
    í™•ë¥  ê¸°ë°˜ í† í° ë¶„í• ì´ ê°€ëŠ¥í•œ í† í¬ë‚˜ì´ì €ë¥¼ ìƒì„±í•œë‹¤.

    Attributes:
        console: Rich ì½˜ì†” ì¸ìŠ¤í„´ìŠ¤
        original_tokenizer_dir: ì›ë³¸ BPE í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬
        distilled_tokenizer_dir: ì¦ë¥˜ëœ Unigram í† í¬ë‚˜ì´ì € ì €ì¥ ë””ë ‰í† ë¦¬
        corpus_dir: í•™ìŠµì— ì‚¬ìš©í•  ì½”í¼ìŠ¤ ë””ë ‰í† ë¦¬
    """

    @staticmethod
    def configure_parser(subparsers: SubparsersLike) -> None:
        """ì„œë¸Œì»¤ë§¨ë“œ íŒŒì„œë¥¼ ì„¤ì •í•œë‹¤.

        Args:
            subparsers: ì„œë¸ŒíŒŒì„œ ì•¡ì…˜ ê°ì²´
        """
        parser = subparsers.add_parser(
            "distill-tokenizer", help="BPE -> Unigram distillation", formatter_class=CliHelpFormatter
        )
        parser.add_argument(
            "--original-tokenizer-dir",
            type=Path,
            default=TOKENIZER_ORIGINAL_DIR,
            help="ì›ë³¸ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬",
        )
        parser.add_argument(
            "--distilled-tokenizer-dir",
            type=Path,
            default=TOKENIZER_DISTILLED_UNIGRAM_DIR,
            help="ì¦ë¥˜ëœ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬",
        )
        parser.add_argument("--corpus-dir", type=Path, default=CORPORA_CLEANED_DIR, help="í•™ìŠµ ì½”í¼ìŠ¤ ë””ë ‰í† ë¦¬")

    def __init__(
        self,
        console: Console,
        original_tokenizer_dir: Path,
        distilled_tokenizer_dir: Path,
        corpus_dir: Path,
    ):
        self.console = console
        self.original_tokenizer_dir = original_tokenizer_dir
        self.distilled_tokenizer_dir = distilled_tokenizer_dir
        self.corpus_dir = corpus_dir

    def execute(self) -> dict[str, Any]:
        """í† í¬ë‚˜ì´ì € ì¦ë¥˜ë¥¼ ì‹¤í–‰í•œë‹¤.

        Returns:
            ì¦ë¥˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (output_dir, vocab_size, original_vocab_size)
        """
        from gpt2_ivr.tokenizer import distill_unigram_tokenizer
        result = distill_unigram_tokenizer(
            original_tokenizer_dir=self.original_tokenizer_dir,
            distilled_tokenizer_dir=self.distilled_tokenizer_dir,
            corpus_dir=self.corpus_dir,
        )

        # Rich í…Œì´ë¸”ë¡œ ê²°ê³¼ ì¶œë ¥
        table = Table(title="ğŸ”¬ í† í¬ë‚˜ì´ì € ì¦ë¥˜ ê²°ê³¼", show_header=True, title_style="bold green")
        table.add_column("í•­ëª©", style="bold cyan", width=25)
        table.add_column("ê°’", style="yellow", justify="right")

        table.add_row("ì›ë³¸ vocab í¬ê¸°", f"{result['original_vocab_size']:,}ê°œ")
        table.add_row("ì¦ë¥˜ vocab í¬ê¸°", f"{result['vocab_size']:,}ê°œ")
        vocab_diff = result["vocab_size"] - result["original_vocab_size"]
        diff_style = "green" if vocab_diff == 0 else "red" if vocab_diff < 0 else "yellow"
        table.add_row("ì°¨ì´", f"[{diff_style}]{vocab_diff:+,}ê°œ[/{diff_style}]")
        table.add_row("", "")  # ë¹ˆ ì¤„
        table.add_row("ì €ì¥ ê²½ë¡œ", str(result["output_dir"]))

        self.console.print()
        self.console.print(table)
        self.console.print()

        # ì„±ê³µ ë©”ì‹œì§€
        self.console.print(
            Panel(
                "[bold green]âœ… Unigram í† í¬ë‚˜ì´ì € ì¦ë¥˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤[/bold green]",
                border_style="green",
                padding=(1, 2),
            )
        )
        self.console.print()

        return {
            "output_dir": result["output_dir"],
            "vocab_size": result["vocab_size"],
            "original_vocab_size": result["original_vocab_size"],
        }

    def get_name(self) -> str:
        """ì»¤ë§¨ë“œ ì´ë¦„ì„ ë°˜í™˜í•œë‹¤.

        Returns:
            ì»¤ë§¨ë“œ ì´ë¦„ "distill-tokenizer"
        """
        return "distill-tokenizer"
