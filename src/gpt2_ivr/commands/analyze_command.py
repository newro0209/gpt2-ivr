"""í† í° ë¹ˆë„ ë¶„ì„ ì»¤ë§¨ë“œ.

ì½”í¼ìŠ¤ íŒŒì¼ì„ BPE í† í¬ë‚˜ì´ì €ë¡œ í† í°í™”í•˜ì—¬ ê° í† í°ì˜ ì¶œí˜„ ë¹ˆë„ë¥¼
ë¶„ì„í•˜ê³  ì‹œí€€ìŠ¤ íŒŒì¼ê³¼ ë¹ˆë„ í†µê³„ë¥¼ ìƒì„±í•œë‹¤.
"""

from __future__ import annotations

import logging
from collections import Counter
from pathlib import Path
from typing import Any

from rich.console import Console
from rich.panel import Panel
from rich.progress import track
from rich.table import Table

from gpt2_ivr.analysis.token_frequency import (
    analyze_token_frequency,
    write_frequency_parquet,
)

from .base import Command

logger = logging.getLogger(__name__)
console = Console()


class AnalyzeCommand(Command):
    """í† í° ë¹ˆë„ ë¶„ì„ ì»¤ë§¨ë“œ.

    ì½”í¼ìŠ¤ë¥¼ í† í°í™”í•˜ì—¬ BPE í† í° ID ì‹œí€€ìŠ¤ì™€ ë¹ˆë„ í†µê³„ë¥¼ ìƒì„±í•œë‹¤.
    ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ ëŒ€ìš©ëŸ‰ ì½”í¼ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.

    Attributes:
        input_dir: ì½”í¼ìŠ¤ ì…ë ¥ ë””ë ‰í† ë¦¬
        output_sequences: BPE í† í° ì‹œí€€ìŠ¤ ì¶œë ¥ ê²½ë¡œ
        output_frequency: í† í° ë¹ˆë„ parquet ì¶œë ¥ ê²½ë¡œ
        tokenizer_dir: ì›ë³¸ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬
        workers: ìŠ¤ë ˆë“œ ì›Œì»¤ ìˆ˜ (0ì´ë©´ CPU - 1)
        chunk_size: ìŠ¤ë ˆë“œ ì²­í¬ í¬ê¸° (0ì´ë©´ ìë™ ì„¤ì •)
        max_texts: ì²˜ë¦¬í•  ìµœëŒ€ í…ìŠ¤íŠ¸ ìˆ˜ (0ì´ë©´ ì „ì²´)
        text_key: json/jsonl í…ìŠ¤íŠ¸ í‚¤
        encoding: ì…ë ¥ íŒŒì¼ ì¸ì½”ë”©
    """

    def __init__(
        self,
        input_dir: Path,
        output_sequences: Path,
        output_frequency: Path,
        tokenizer_dir: Path,
        workers: int,
        chunk_size: int,
        max_texts: int,
        text_key: str,
        encoding: str,
    ):
        self.input_dir = input_dir
        self.output_sequences = output_sequences
        self.output_frequency = output_frequency
        self.tokenizer_dir = tokenizer_dir
        self.workers = workers
        self.chunk_size = chunk_size
        self.max_texts = max_texts
        self.text_key = text_key
        self.encoding = encoding

    def execute(self, **kwargs: Any) -> dict[str, Any]:
        """í† í° ë¹ˆë„ ë¶„ì„ì„ ì‹¤í–‰í•œë‹¤.

        ì½”í¼ìŠ¤ë¥¼ ì½ì–´ í† í°í™”í•˜ê³ , í† í° ID ì‹œí€€ìŠ¤ íŒŒì¼ê³¼ ë¹ˆë„ í†µê³„ íŒŒì¼ì„ ìƒì„±í•œë‹¤.

        Args:
            **kwargs: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (sequences_path, frequency_path, total_tokens, unique_tokens)
        """
        encoded_chunks_iterator, tokenizer = analyze_token_frequency(
            input_dir=self.input_dir,
            inputs=[],
            output_frequency=self.output_frequency,
            tokenizer_dir=self.tokenizer_dir,
            workers=self.workers,
            chunk_size=self.chunk_size,
            max_texts=self.max_texts,
            text_key=self.text_key,
            encoding=self.encoding,
        )

        counter: Counter[int] = Counter()
        self.output_sequences.parent.mkdir(parents=True, exist_ok=True)
        with self.output_sequences.open("w", encoding="utf-8") as handle:
            for chunk_ids in track(encoded_chunks_iterator, description="ğŸ” í† í°í™”"):
                for token_ids in chunk_ids:
                    counter.update(token_ids)
                    handle.write(" ".join(str(token_id) for token_id in token_ids))
                    handle.write("\n")

        # ê²°ê³¼ë¬¼ ì €ì¥ (ë¹ˆë„ parquet)
        self.output_frequency.parent.mkdir(parents=True, exist_ok=True)
        write_frequency_parquet(counter, self.output_frequency)

        total_tokens = sum(counter.values())
        unique_tokens = len(counter)

        # Rich í…Œì´ë¸”ë¡œ ê²°ê³¼ ì¶œë ¥
        table = Table(title="í† í° ë¹ˆë„ ë¶„ì„ ê²°ê³¼", show_header=False, title_style="bold green")
        table.add_column("í•­ëª©", style="cyan", width=20)
        table.add_column("ê°’", style="yellow")

        table.add_row("ì´ í† í°", f"{total_tokens:,}ê°œ")
        table.add_row("ê³ ìœ  í† í°", f"{unique_tokens:,}ê°œ")
        table.add_row("ë¹ˆë„ íŒŒì¼", str(self.output_frequency))
        table.add_row("ì‹œí€€ìŠ¤ íŒŒì¼", str(self.output_sequences))

        console.print()
        console.print(table)
        console.print()

        return {
            "sequences_path": self.output_sequences,
            "frequency_path": self.output_frequency,
            "total_tokens": total_tokens,
            "unique_tokens": unique_tokens,
        }

    def get_name(self) -> str:
        """ì»¤ë§¨ë“œ ì´ë¦„ì„ ë°˜í™˜í•œë‹¤.

        Returns:
            ì»¤ë§¨ë“œ ì´ë¦„ "analyze"
        """
        return "analyze"
