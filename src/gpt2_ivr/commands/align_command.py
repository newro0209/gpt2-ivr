"""ì„ë² ë”© ì •ë ¬ ì»¤ë§¨ë“œ.

ì›ë³¸ ëª¨ë¸ì—ì„œ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ê³ , ì¬í• ë‹¹ ê·œì¹™ì— ë”°ë¼ ì¬ì •ë ¬í•œ í›„
ì‹ ê·œ í† í°ì˜ ì„ë² ë”©ì„ ì´ˆê¸°í™”í•˜ëŠ” 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜í–‰í•œë‹¤.
"""

from __future__ import annotations

import logging
from pathlib import Path
from typing import Any

from gpt2_ivr.commands.base import Command
from gpt2_ivr.embedding import (
    extract_embeddings,
    initialize_new_token_embeddings,
    reorder_embeddings,
)


class AlignCommand(Command):
    """ì„ë² ë”© ì¶”ì¶œ, ì¬ì •ë ¬ ë° ì´ˆê¸°í™”ë¥¼ ìˆ˜í–‰í•œë‹¤.

    1ë‹¨ê³„: ì›ë³¸ ëª¨ë¸ ì„ë² ë”© ì¶”ì¶œ (wte, wpe)
    2ë‹¨ê³„: ì¬í• ë‹¹ ê·œì¹™ì— ë”°ë¼ ì„ë² ë”© ì¬ì •ë ¬
    3ë‹¨ê³„: ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™” (mean, random, zeros)

    Attributes:
        logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
        model_name: GPT-2 ëª¨ë¸ ì´ë¦„
        original_tokenizer_dir: ì›ë³¸ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬
        remapped_tokenizer_dir: ì¬í• ë‹¹ í† í¬ë‚˜ì´ì € ë””ë ‰í† ë¦¬
        remap_rules_path: ì¬í• ë‹¹ ê·œì¹™ YAML íŒŒì¼ ê²½ë¡œ
        embeddings_output_dir: ì„ë² ë”© ì¶œë ¥ ë””ë ‰í† ë¦¬
        init_strategy: ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™” ì „ëµ
    """

    def __init__(
        self,
        model_name: str,
        original_tokenizer_dir: Path,
        remapped_tokenizer_dir: Path,
        remap_rules_path: Path,
        embeddings_output_dir: Path,
        init_strategy: str,
    ) -> None:
        self.logger = logging.getLogger("gpt2_ivr.align")
        self.model_name = model_name
        self.original_tokenizer_dir = original_tokenizer_dir
        self.remapped_tokenizer_dir = remapped_tokenizer_dir
        self.remap_rules_path = remap_rules_path
        self.embeddings_output_dir = embeddings_output_dir
        self.init_strategy = init_strategy

    def execute(self, **kwargs: Any) -> dict[str, Any]:
        """ì„ë² ë”© ì •ë ¬ì„ ì‹¤í–‰í•œë‹¤.

        ì„ë² ë”© ì¶”ì¶œ, ì¬ì •ë ¬, ì´ˆê¸°í™”ì˜ 3ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤.

        Args:
            **kwargs: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

        Returns:
            ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (status, extract_result, reorder_result, init_result, embeddings_dir)
        """
        self.logger.info("ğŸš€ align ë‹¨ê³„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

        # 1. ì›ë³¸ ëª¨ë¸ì—ì„œ ì„ë² ë”© ì¶”ì¶œ
        self.logger.info("=" * 60)
        self.logger.info("1ë‹¨ê³„: ì›ë³¸ ëª¨ë¸ ì„ë² ë”© ì¶”ì¶œ")
        self.logger.info("=" * 60)

        extract_result = extract_embeddings(
            model_name=self.model_name,
            output_dir=self.embeddings_output_dir,
            logger=self.logger,
        )

        # 2. Remap ê·œì¹™ì— ë”°ë¼ ì„ë² ë”© ì¬ì •ë ¬
        self.logger.info("=" * 60)
        self.logger.info("2ë‹¨ê³„: ì„ë² ë”© ì¬ì •ë ¬")
        self.logger.info("=" * 60)

        reorder_result = reorder_embeddings(
            original_wte_path=extract_result["wte"],
            original_tokenizer_dir=self.original_tokenizer_dir,
            remapped_tokenizer_dir=self.remapped_tokenizer_dir,
            remap_rules_path=self.remap_rules_path,
            output_dir=self.embeddings_output_dir,
            logger=self.logger,
        )

        # 3. ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™”
        self.logger.info("=" * 60)
        self.logger.info("3ë‹¨ê³„: ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™”")
        self.logger.info("=" * 60)

        init_result = initialize_new_token_embeddings(
            aligned_wte_path=reorder_result["aligned_wte"],
            original_tokenizer_dir=self.original_tokenizer_dir,
            remapped_tokenizer_dir=self.remapped_tokenizer_dir,
            remap_rules_path=self.remap_rules_path,
            output_dir=self.embeddings_output_dir,
            init_strategy=self.init_strategy,
            logger=self.logger,
        )

        self.logger.info("=" * 60)
        self.logger.info("âœ… align ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.logger.info("=" * 60)

        return {
            "status": "success",
            "extract_result": extract_result,
            "reorder_result": reorder_result,
            "init_result": init_result,
            "embeddings_dir": str(self.embeddings_output_dir),
        }

    def get_name(self) -> str:
        """ì»¤ë§¨ë“œ ì´ë¦„ì„ ë°˜í™˜í•œë‹¤.

        Returns:
            ì»¤ë§¨ë“œ ì´ë¦„ "align"
        """
        return "align"
