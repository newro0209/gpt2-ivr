"""Embedding Alignment Command"""

from __future__ import annotations

from pathlib import Path
from typing import Any

from gpt2_ivr.commands.base import Command
from gpt2_ivr.embedding import (
    extract_embeddings,
    initialize_new_token_embeddings,
    reorder_embeddings,
)
from gpt2_ivr.utils.logging_config import get_logger


class AlignCommand(Command):
    """Align Command - ì„ë² ë”© ì¶”ì¶œ, ì¬ì •ë ¬ ë° ì´ˆê¸°í™”ë¥¼ ìˆ˜í–‰í•œë‹¤."""

    def __init__(
        self,
        model_name: str = "openai-community/gpt2",
        original_tokenizer_dir: Path = Path("artifacts/tokenizers/original"),
        remapped_tokenizer_dir: Path = Path("artifacts/tokenizers/remapped"),
        remap_rules_path: Path = Path("src/gpt2_ivr/tokenizer/remap_rules.yaml"),
        embeddings_output_dir: Path = Path("artifacts/embeddings"),
        init_strategy: str = "mean",
    ) -> None:
        self.logger = get_logger("gpt2_ivr.align")
        self.model_name = model_name
        self.original_tokenizer_dir = original_tokenizer_dir
        self.remapped_tokenizer_dir = remapped_tokenizer_dir
        self.remap_rules_path = remap_rules_path
        self.embeddings_output_dir = embeddings_output_dir
        self.init_strategy = init_strategy

    def execute(self, **kwargs: Any) -> dict[str, Any]:
        """ì»¤ë§¨ë“œ ì‹¤í–‰ ë¡œì§"""
        self.logger.info("ğŸš€ Align Command ì‹œì‘")

        # 1. ì›ë³¸ ëª¨ë¸ì—ì„œ ì„ë² ë”© ì¶”ì¶œ
        self.logger.info("=" * 60)
        self.logger.info("1ë‹¨ê³„: ì›ë³¸ ëª¨ë¸ ì„ë² ë”© ì¶”ì¶œ")
        self.logger.info("=" * 60)

        extract_result = extract_embeddings(
            model_name=self.model_name,
            output_dir=self.embeddings_output_dir,
            logger=self.logger,
        )

        # 2. Remap ê·œì¹™ì— ë”°ë¼ ì„ë² ë”© ì¬ì •ë ¬
        self.logger.info("=" * 60)
        self.logger.info("2ë‹¨ê³„: ì„ë² ë”© ì¬ì •ë ¬")
        self.logger.info("=" * 60)

        reorder_result = reorder_embeddings(
            original_wte_path=extract_result["wte"],
            original_tokenizer_dir=self.original_tokenizer_dir,
            remapped_tokenizer_dir=self.remapped_tokenizer_dir,
            remap_rules_path=self.remap_rules_path,
            output_dir=self.embeddings_output_dir,
            logger=self.logger,
        )

        # 3. ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™”
        self.logger.info("=" * 60)
        self.logger.info("3ë‹¨ê³„: ì‹ ê·œ í† í° ì„ë² ë”© ì´ˆê¸°í™”")
        self.logger.info("=" * 60)

        init_result = initialize_new_token_embeddings(
            aligned_wte_path=reorder_result["aligned_wte"],
            original_tokenizer_dir=self.original_tokenizer_dir,
            remapped_tokenizer_dir=self.remapped_tokenizer_dir,
            remap_rules_path=self.remap_rules_path,
            output_dir=self.embeddings_output_dir,
            init_strategy=self.init_strategy,
            logger=self.logger,
        )

        self.logger.info("=" * 60)
        self.logger.info("âœ… Align Command ì™„ë£Œ")
        self.logger.info("=" * 60)

        return {
            "status": "success",
            "extract_result": extract_result,
            "reorder_result": reorder_result,
            "init_result": init_result,
            "embeddings_dir": str(self.embeddings_output_dir),
        }

    def get_name(self) -> str:
        """ì»¤ë§¨ë“œ ì´ë¦„ ë°˜í™˜"""
        return "align"
