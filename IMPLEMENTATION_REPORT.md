# í•™ìŠµ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ ë³´ê³ ì„œ

## ğŸ“‹ ê°œìš”

GPT-2 IVR í”„ë¡œì íŠ¸ì˜ í•™ìŠµ(train) ë° ì„ë² ë”© ì •ë ¬(align) ê¸°ëŠ¥ì„ ì™„ì„±í–ˆìŠµë‹ˆë‹¤.

## âœ… êµ¬í˜„ ì™„ë£Œ í•­ëª©

### 1. í•™ìŠµ ëª¨ë“ˆ (`src/gpt2_ivr/training/`)

#### `train.py` - í•µì‹¬ í•™ìŠµ ë¡œì§

- **`train_model()` í•¨ìˆ˜**: Hugging Face Transformers ê¸°ë°˜ í•™ìŠµ ì‹¤í–‰
  - sft_config.yamlì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œ
  - ì¬í• ë‹¹ëœ í† í¬ë‚˜ì´ì € ë¡œë“œ (`artifacts/tokenizers/remapped/`)
  - GPT-2 ëª¨ë¸ ë¡œë“œ ë° vocab size ì¡°ì •
  - ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬
  - TrainingArguments ì„¤ì •
  - Trainerë¥¼ ì‚¬ìš©í•œ í•™ìŠµ ì‹¤í–‰
  - ì²´í¬í¬ì¸íŠ¸ ë° ìµœì¢… ëª¨ë¸ ì €ì¥

- **`load_training_config()` í•¨ìˆ˜**: YAML ì„¤ì • íŒŒì¼ ë¡œë“œ

- **`load_dataset()` í•¨ìˆ˜**: ì½”í¼ìŠ¤ ë¡œë“œ ë° í† í¬ë‚˜ì´ì§•
  - `artifacts/corpora/cleaned/`ì—ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
  - í† í¬ë‚˜ì´ì €ë¡œ ì „ì²˜ë¦¬
  - Trainer í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

#### `__init__.py`
- `train_model` í•¨ìˆ˜ export

### 2. ì„ë² ë”© ëª¨ë“ˆ (`src/gpt2_ivr/embedding/`)

#### `extract.py` - ì„ë² ë”© ì¶”ì¶œ

- **`extract_embeddings()` í•¨ìˆ˜**
  - ì‚¬ì „í•™ìŠµëœ GPT-2 ëª¨ë¸ì—ì„œ ì„ë² ë”© ì¶”ì¶œ
  - Word Token Embeddings (wte) ì¶”ì¶œ
  - Language Model Head (lm_head) ì¶”ì¶œ
  - PyTorch í…ì„œë¡œ ì €ì¥

#### `reorder.py` - ì„ë² ë”© ì¬ì •ë ¬

- **`reorder_embeddings()` í•¨ìˆ˜**
  - ì›ë³¸ ì„ë² ë”© ë¡œë“œ
  - ì¬í• ë‹¹ ê·œì¹™(remap_rules.yaml) ë¡œë“œ
  - ìƒˆ vocab sizeì— ë§ëŠ” ì„ë² ë”© í…ì„œ ìƒì„±
  - ê¸°ì¡´ í† í°: ì›ë³¸ ì„ë² ë”© ë³µì‚¬
  - ì¬í• ë‹¹ëœ í† í°: ì›ë³¸ í† í°ì˜ ì„ë² ë”© ë³µì‚¬
  - ìƒˆ í† í°: í‰ê· ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
  - ì¬ì •ë ¬ëœ ì„ë² ë”© ì €ì¥

#### `init_new.py` - ëª¨ë¸ ì´ˆê¸°í™”

- **`initialize_new_embeddings()` í•¨ìˆ˜**
  - ì¬ì •ë ¬ëœ ì„ë² ë”© ë¡œë“œ
  - GPT-2 ëª¨ë¸ ë¡œë“œ ë° vocab size ì¡°ì •
  - ì¬ì •ë ¬ëœ ì„ë² ë”©ì„ ëª¨ë¸ì— ì ìš©
  - ì´ˆê¸°í™”ëœ ëª¨ë¸ ì €ì¥

#### `__init__.py`
- ì„¸ í•¨ìˆ˜ ëª¨ë‘ export

### 3. ì»¤ë§¨ë“œ êµ¬í˜„ (`src/gpt2_ivr/commands/`)

#### `train_command.py` - TrainCommand

- `train_model()` í•¨ìˆ˜ í˜¸ì¶œ
- ë¡œê¹… í†µí•©
- CLI ì¸ì ì²˜ë¦¬:
  - `--model-name`: ê¸°ë³¸ ëª¨ë¸ (ê¸°ë³¸ê°’: openai-community/gpt2)
  - `--tokenizer-path`: í† í¬ë‚˜ì´ì € ê²½ë¡œ (ê¸°ë³¸ê°’: artifacts/tokenizers/remapped)
  - `--dataset-path`: ë°ì´í„°ì…‹ ê²½ë¡œ (ê¸°ë³¸ê°’: artifacts/corpora/cleaned)
  - `--output-dir`: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: artifacts/training/sft_checkpoint)
  - `--config-path`: ì„¤ì • íŒŒì¼ (ê¸°ë³¸ê°’: src/gpt2_ivr/training/sft_config.yaml)

#### `align_command.py` - AlignCommand

- 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:
  1. ì›ë³¸ ëª¨ë¸ ì„ë² ë”© ì¶”ì¶œ (`extract_embeddings`)
  2. ì„ë² ë”© ì¬ì •ë ¬ (`reorder_embeddings`)
  3. ì¬ì •ë ¬ëœ ì„ë² ë”©ì„ ëª¨ë¸ì— ì ìš© (`initialize_new_embeddings`)
- ë¡œê¹… í†µí•©
- CLI ì¸ì ì²˜ë¦¬:
  - `--model-name`: ê¸°ë³¸ ëª¨ë¸
  - `--original-tokenizer-dir`: ì›ë³¸ í† í¬ë‚˜ì´ì €
  - `--remapped-tokenizer-dir`: ì¬í• ë‹¹ í† í¬ë‚˜ì´ì €
  - `--remap-rules-path`: ì¬í• ë‹¹ ê·œì¹™ íŒŒì¼
  - `--embeddings-dir`: ì„ë² ë”© ì €ì¥ ë””ë ‰í† ë¦¬

### 4. CLI í†µí•© (`src/gpt2_ivr/cli.py`)

- `align` ì„œë¸Œì»¤ë§¨ë“œ ì¶”ê°€
  - ì¸ì íŒŒì„œ êµ¬í˜„
  - íŒ©í† ë¦¬ í•¨ìˆ˜ êµ¬í˜„
- `train` ì„œë¸Œì»¤ë§¨ë“œ ì¶”ê°€
  - ì¸ì íŒŒì„œ êµ¬í˜„
  - íŒ©í† ë¦¬ í•¨ìˆ˜ êµ¬í˜„

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
í•™ìŠµ íŒŒì´í”„ë¼ì¸:
1. uv run ivr align
   â””â”€> extract_embeddings() â†’ reorder_embeddings() â†’ initialize_new_embeddings()

2. uv run ivr train
   â””â”€> train_model()
       â”œâ”€> load_training_config()
       â”œâ”€> load_dataset()
       â””â”€> Trainer.train()
```

## ğŸ“‚ ìƒì„±ë˜ëŠ” ì‚°ì¶œë¬¼

### align ë‹¨ê³„
```
artifacts/embeddings/
â”œâ”€â”€ original_embeddings.pt      # ì›ë³¸ ëª¨ë¸ ì„ë² ë”©
â”œâ”€â”€ reordered_embeddings.pt     # ì¬ì •ë ¬ëœ ì„ë² ë”©
â””â”€â”€ initialized_model/          # ì¬ì •ë ¬ëœ ì„ë² ë”©ì´ ì ìš©ëœ ëª¨ë¸
```

### train ë‹¨ê³„
```
artifacts/training/sft_checkpoint/
â”œâ”€â”€ checkpoint-500/             # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ (save_stepsë§ˆë‹¤)
â”œâ”€â”€ checkpoint-1000/
â”œâ”€â”€ final_model/                # ìµœì¢… í•™ìŠµëœ ëª¨ë¸
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ tokenizer files
â””â”€â”€ logs/                       # TensorBoard ë¡œê·¸
```

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **í•™ìŠµ í”„ë ˆì„ì›Œí¬**: Hugging Face Transformers + Trainer API
- **ëª¨ë¸**: GPT-2 (Causal Language Model)
- **ë°ì´í„°**: Language Modeling (MLM ë¯¸ì‚¬ìš©)
- **ë¡œê¹…**: Python logging + TensorBoard
- **ì„¤ì •**: YAML (sft_config.yaml, accelerate_config.yaml)

## ğŸš€ ì‚¬ìš©ë²•

### 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# 1ë‹¨ê³„: ì´ˆê¸°í™”
uv run ivr init

# 2ë‹¨ê³„: BPE í† í° ë¶„ì„
uv run ivr analyze

# 3ë‹¨ê³„: í† í¬ë‚˜ì´ì € ì¦ë¥˜
uv run ivr distill-tokenizer

# 4ë‹¨ê³„: IVR í›„ë³´ ì„ ì •
uv run ivr select

# 5ë‹¨ê³„: í† í° ì¬í• ë‹¹
uv run ivr remap

# 6ë‹¨ê³„: ì„ë² ë”© ì •ë ¬ (âœ¨ ìƒˆë¡œ êµ¬í˜„)
uv run ivr align

# 7ë‹¨ê³„: í•™ìŠµ (âœ¨ ìƒˆë¡œ êµ¬í˜„)
uv run ivr train
```

### 2. ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰

```bash
# align ì»¤ìŠ¤í…€ ì‹¤í–‰
uv run ivr align \
  --model-name openai-community/gpt2 \
  --embeddings-dir artifacts/embeddings_custom

# train ì»¤ìŠ¤í…€ ì‹¤í–‰
uv run ivr train \
  --tokenizer-path artifacts/tokenizers/remapped \
  --dataset-path artifacts/corpora/cleaned \
  --output-dir artifacts/training/custom_run \
  --config-path src/gpt2_ivr/training/sft_config.yaml
```

## ğŸ“Š í•™ìŠµ ì„¤ì • (sft_config.yaml)

```yaml
# í•˜ì´í¼íŒŒë¼ë¯¸í„°
num_train_epochs: 3
per_device_train_batch_size: 8
learning_rate: 5.0e-5
weight_decay: 0.01
lr_scheduler_type: "cosine"
warmup_ratio: 0.03

# ë¡œê¹… ë° ì €ì¥
logging_steps: 10
save_steps: 500
save_total_limit: 2

# ê¸°íƒ€
seed: 42
report_to: "tensorboard"
```

## âœ¨ ì£¼ìš” íŠ¹ì§•

1. **ì™„ì „í•œ íƒ€ì… íŒíŠ¸**: ëª¨ë“  í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ ì ìš©
2. **í•œêµ­ì–´ ë¬¸ì„œí™”**: ì£¼ì„, ë¡œê¹… ë©”ì‹œì§€ ëª¨ë‘ í•œêµ­ì–´
3. **ì´ëª¨ì§€ ë¡œê¹…**: ê°€ë…ì„±ì„ ìœ„í•œ ì´ëª¨ì§€ í™œìš©
4. **ì—ëŸ¬ ì²˜ë¦¬**: ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ ë° ì˜ˆì™¸ ì²˜ë¦¬
5. **í™•ì¥ ê°€ëŠ¥ì„±**: CLI ì¸ìë¥¼ í†µí•œ ìœ ì—°í•œ ì„¤ì •
6. **ì¬í˜„ì„±**: ì„¤ì • íŒŒì¼ ê¸°ë°˜ í•™ìŠµ

## ğŸ§ª ê²€ì¦ ì™„ë£Œ

- âœ… Python êµ¬ë¬¸ ê²€ì¦
- âœ… í•¨ìˆ˜ ì •ì˜ ê²€ì¦
- âœ… í´ë˜ìŠ¤ ì •ì˜ ê²€ì¦
- âœ… ëª¨ë“ˆ export ê²€ì¦
- âœ… CLI í†µí•© ê²€ì¦

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„ (ì„ íƒ ì‚¬í•­)

1. **í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±**: `tests/` ë””ë ‰í† ë¦¬ì— ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ê°€
2. **í‰ê°€ íŒŒì´í”„ë¼ì¸**: í•™ìŠµ í›„ ëª¨ë¸ í‰ê°€ ê¸°ëŠ¥ ì¶”ê°€
3. **ë¶„ì‚° í•™ìŠµ**: accelerate_config.yaml í™œìš©í•œ ë©€í‹° GPU ì§€ì›
4. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: Optuna ë“±ì„ í™œìš©í•œ ìë™ íŠœë‹

## ğŸ¯ ê²°ë¡ 

í•™ìŠµ ê¸°ëŠ¥ì´ ì™„ì „íˆ êµ¬í˜„ë˜ì–´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
ì´ì œ BPE â†’ Unigram í† í¬ë‚˜ì´ì € ì „í™˜ í›„ IVRì„ ìˆ˜í–‰í•˜ê³ ,
ì¬ì •ë ¬ëœ ì„ë² ë”©ìœ¼ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
